{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow neural networks in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a shallow neural network to classift MNIST digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set seed for reproducibility   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11476992/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_test = X_test.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.07058824,  0.07058824,\n",
       "        0.07058824,  0.49411765,  0.53333336,  0.68627453,  0.10196079,\n",
       "        0.65098041,  1.        ,  0.96862745,  0.49803922,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.11764706,  0.14117648,  0.36862746,  0.60392159,\n",
       "        0.66666669,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.88235295,  0.67450982,  0.99215686,  0.94901961,\n",
       "        0.7647059 ,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.19215687,  0.93333334,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.98431373,  0.36470589,\n",
       "        0.32156864,  0.32156864,  0.21960784,  0.15294118,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.07058824,  0.85882354,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.7764706 ,  0.71372551,\n",
       "        0.96862745,  0.94509804,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.3137255 ,  0.61176473,  0.41960785,  0.99215686,  0.99215686,\n",
       "        0.80392158,  0.04313726,  0.        ,  0.16862746,  0.60392159,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.05490196,\n",
       "        0.00392157,  0.60392159,  0.99215686,  0.35294119,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.54509807,\n",
       "        0.99215686,  0.74509805,  0.00784314,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.04313726,  0.74509805,  0.99215686,\n",
       "        0.27450982,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.13725491,  0.94509804,  0.88235295,  0.627451  ,\n",
       "        0.42352942,  0.00392157,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.31764707,  0.94117647,  0.99215686,  0.99215686,  0.46666667,\n",
       "        0.09803922,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.17647059,\n",
       "        0.72941178,  0.99215686,  0.99215686,  0.58823532,  0.10588235,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.0627451 ,  0.36470589,\n",
       "        0.98823529,  0.99215686,  0.73333335,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.97647059,  0.99215686,\n",
       "        0.97647059,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.18039216,  0.50980395,\n",
       "        0.71764708,  0.99215686,  0.99215686,  0.81176472,  0.00784314,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.15294118,\n",
       "        0.58039218,  0.89803922,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.98039216,  0.71372551,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.09411765,  0.44705883,  0.86666667,  0.99215686,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.78823531,  0.30588236,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.09019608,  0.25882354,  0.83529413,  0.99215686,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.7764706 ,  0.31764707,\n",
       "        0.00784314,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.07058824,  0.67058825,  0.85882354,\n",
       "        0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.7647059 ,\n",
       "        0.3137255 ,  0.03529412,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.21568628,  0.67450982,\n",
       "        0.88627452,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.95686275,  0.52156866,  0.04313726,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.53333336,  0.99215686,  0.99215686,  0.99215686,\n",
       "        0.83137256,  0.52941179,  0.51764709,  0.0627451 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designing neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(784,)),\n",
    "    Activation('sigmoid'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 2s - loss: 0.0915 - acc: 0.0897 - val_loss: 0.0911 - val_acc: 0.0966\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0908 - acc: 0.1072 - val_loss: 0.0905 - val_acc: 0.1185\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0902 - acc: 0.143 - 1s - loss: 0.0902 - acc: 0.1441 - val_loss: 0.0900 - val_acc: 0.1551\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0898 - acc: 0.1981 - val_loss: 0.0896 - val_acc: 0.2114\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0894 - acc: 0.2454 - val_loss: 0.0892 - val_acc: 0.2475\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0891 - acc: 0.2746 - val_loss: 0.0889 - val_acc: 0.2752\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0887 - acc: 0.2941 - val_loss: 0.0885 - val_acc: 0.2908\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0883 - acc: 0.3041 - val_loss: 0.0882 - val_acc: 0.3038\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0880 - acc: 0.3117 - val_loss: 0.0878 - val_acc: 0.3105\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0876 - acc: 0.3157 - val_loss: 0.0875 - val_acc: 0.3156\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0873 - acc: 0.3191 - val_loss: 0.0871 - val_acc: 0.3194\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0869 - acc: 0.3216 - val_loss: 0.0868 - val_acc: 0.3215\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0866 - acc: 0.3245 - val_loss: 0.0864 - val_acc: 0.3246\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0862 - acc: 0.3246 - val_loss: 0.0860 - val_acc: 0.3262\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0859 - acc: 0.3272 - val_loss: 0.0857 - val_acc: 0.3279\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0855 - acc: 0.3283 - val_loss: 0.0853 - val_acc: 0.3298\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0851 - acc: 0.3300 - val_loss: 0.0849 - val_acc: 0.3307\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0848 - acc: 0.3314 - val_loss: 0.0845 - val_acc: 0.3326\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0844 - acc: 0.3334 - val_loss: 0.0841 - val_acc: 0.3348\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0840 - acc: 0.3349 - val_loss: 0.0837 - val_acc: 0.3378\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0836 - acc: 0.3367 - val_loss: 0.0833 - val_acc: 0.3407\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0832 - acc: 0.3398 - val_loss: 0.0829 - val_acc: 0.3445\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0828 - acc: 0.3428 - val_loss: 0.0825 - val_acc: 0.3487\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0823 - acc: 0.3461 - val_loss: 0.0821 - val_acc: 0.3544\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0819 - acc: 0.3495 - val_loss: 0.0816 - val_acc: 0.3610\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0815 - acc: 0.3553 - val_loss: 0.0812 - val_acc: 0.3656\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0810 - acc: 0.3600 - val_loss: 0.0807 - val_acc: 0.3714\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0806 - acc: 0.3666 - val_loss: 0.0803 - val_acc: 0.3766\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0802 - acc: 0.3724 - val_loss: 0.0798 - val_acc: 0.3833\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0797 - acc: 0.3786 - val_loss: 0.0794 - val_acc: 0.3914\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0792 - acc: 0.3863 - val_loss: 0.0789 - val_acc: 0.3988\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0788 - acc: 0.3934 - val_loss: 0.0784 - val_acc: 0.4063\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0783 - acc: 0.4012 - val_loss: 0.0779 - val_acc: 0.4153\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0778 - acc: 0.4083 - val_loss: 0.0775 - val_acc: 0.4241\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0773 - acc: 0.4182 - val_loss: 0.0770 - val_acc: 0.4329\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0769 - acc: 0.4264 - val_loss: 0.0765 - val_acc: 0.4404\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0764 - acc: 0.4360 - val_loss: 0.0760 - val_acc: 0.4493\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0759 - acc: 0.4461 - val_loss: 0.0755 - val_acc: 0.4583\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0754 - acc: 0.4541 - val_loss: 0.0750 - val_acc: 0.4687\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0749 - acc: 0.4643 - val_loss: 0.0745 - val_acc: 0.4767\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0744 - acc: 0.4748 - val_loss: 0.0740 - val_acc: 0.4887\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0740 - acc: 0.4842 - val_loss: 0.0735 - val_acc: 0.4978\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0735 - acc: 0.4926 - val_loss: 0.0730 - val_acc: 0.5067\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0730 - acc: 0.5027 - val_loss: 0.0725 - val_acc: 0.5162\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0725 - acc: 0.5113 - val_loss: 0.0720 - val_acc: 0.5246\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0720 - acc: 0.5207 - val_loss: 0.0715 - val_acc: 0.5309\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0715 - acc: 0.5282 - val_loss: 0.0710 - val_acc: 0.5398\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0710 - acc: 0.5367 - val_loss: 0.0705 - val_acc: 0.5463\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0705 - acc: 0.5437 - val_loss: 0.0700 - val_acc: 0.5530\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0700 - acc: 0.5511 - val_loss: 0.0695 - val_acc: 0.5594\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0695 - acc: 0.5586 - val_loss: 0.0690 - val_acc: 0.5659\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0691 - acc: 0.5644 - val_loss: 0.0685 - val_acc: 0.5722\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0686 - acc: 0.5712 - val_loss: 0.0681 - val_acc: 0.5771\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0681 - acc: 0.5764 - val_loss: 0.0676 - val_acc: 0.5816\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0676 - acc: 0.5813 - val_loss: 0.0671 - val_acc: 0.5879\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0671 - acc: 0.5866 - val_loss: 0.0666 - val_acc: 0.5932\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0666 - acc: 0.5913 - val_loss: 0.0661 - val_acc: 0.5972\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0662 - acc: 0.5953 - val_loss: 0.0656 - val_acc: 0.6023\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0657 - acc: 0.5999 - val_loss: 0.0651 - val_acc: 0.6061\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0652 - acc: 0.6038 - val_loss: 0.0646 - val_acc: 0.6102\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0647 - acc: 0.6078 - val_loss: 0.0641 - val_acc: 0.6135\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0643 - acc: 0.6116 - val_loss: 0.0637 - val_acc: 0.6163\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s - loss: 0.0638 - acc: 0.6153 - val_loss: 0.0632 - val_acc: 0.6190\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0633 - acc: 0.6190 - val_loss: 0.0627 - val_acc: 0.6228\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0628 - acc: 0.6224 - val_loss: 0.0622 - val_acc: 0.6258\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0624 - acc: 0.6255 - val_loss: 0.0617 - val_acc: 0.6275\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0619 - acc: 0.6290 - val_loss: 0.0613 - val_acc: 0.6310\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0614 - acc: 0.6322 - val_loss: 0.0608 - val_acc: 0.6344\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0610 - acc: 0.6351 - val_loss: 0.0603 - val_acc: 0.6369\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0605 - acc: 0.6376 - val_loss: 0.0599 - val_acc: 0.6397\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0601 - acc: 0.6403 - val_loss: 0.0594 - val_acc: 0.6428\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0596 - acc: 0.6431 - val_loss: 0.0589 - val_acc: 0.6449\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0592 - acc: 0.6455 - val_loss: 0.0585 - val_acc: 0.6473\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0587 - acc: 0.6481 - val_loss: 0.0580 - val_acc: 0.6492\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0583 - acc: 0.6504 - val_loss: 0.0576 - val_acc: 0.6502\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0578 - acc: 0.6533 - val_loss: 0.0571 - val_acc: 0.6531\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0574 - acc: 0.6556 - val_loss: 0.0567 - val_acc: 0.6568\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0569 - acc: 0.6584 - val_loss: 0.0562 - val_acc: 0.6593\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0565 - acc: 0.6612 - val_loss: 0.0558 - val_acc: 0.6623\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0561 - acc: 0.6640 - val_loss: 0.0553 - val_acc: 0.6663\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0556 - acc: 0.6669 - val_loss: 0.0549 - val_acc: 0.6689\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0552 - acc: 0.6696 - val_loss: 0.0545 - val_acc: 0.6731\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0548 - acc: 0.6731 - val_loss: 0.0540 - val_acc: 0.6762\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0544 - acc: 0.6764 - val_loss: 0.0536 - val_acc: 0.6799\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0540 - acc: 0.6796 - val_loss: 0.0532 - val_acc: 0.6834\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0535 - acc: 0.6829 - val_loss: 0.0528 - val_acc: 0.6871\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0531 - acc: 0.6865 - val_loss: 0.0524 - val_acc: 0.6907\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0527 - acc: 0.6899 - val_loss: 0.0519 - val_acc: 0.6945\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0523 - acc: 0.6932 - val_loss: 0.0515 - val_acc: 0.6976\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0519 - acc: 0.6969 - val_loss: 0.0511 - val_acc: 0.7016\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0515 - acc: 0.7003 - val_loss: 0.0507 - val_acc: 0.7070\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0511 - acc: 0.7037 - val_loss: 0.0503 - val_acc: 0.7099\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0508 - acc: 0.7077 - val_loss: 0.0500 - val_acc: 0.7143\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0504 - acc: 0.7117 - val_loss: 0.0496 - val_acc: 0.7192\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0500 - acc: 0.7152 - val_loss: 0.0492 - val_acc: 0.7227\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0496 - acc: 0.7186 - val_loss: 0.0488 - val_acc: 0.7265\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0493 - acc: 0.7218 - val_loss: 0.0484 - val_acc: 0.7296\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0489 - acc: 0.7247 - val_loss: 0.0481 - val_acc: 0.7340\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0485 - acc: 0.7284 - val_loss: 0.0477 - val_acc: 0.7373\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0482 - acc: 0.7318 - val_loss: 0.0473 - val_acc: 0.7401\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0478 - acc: 0.7353 - val_loss: 0.0470 - val_acc: 0.7431\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0475 - acc: 0.7382 - val_loss: 0.0466 - val_acc: 0.7468\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0471 - acc: 0.7412 - val_loss: 0.0463 - val_acc: 0.7499\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0468 - acc: 0.7440 - val_loss: 0.0459 - val_acc: 0.7530\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0464 - acc: 0.7463 - val_loss: 0.0456 - val_acc: 0.7556\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0461 - acc: 0.7496 - val_loss: 0.0452 - val_acc: 0.7575\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0458 - acc: 0.7519 - val_loss: 0.0449 - val_acc: 0.7601\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0455 - acc: 0.7540 - val_loss: 0.0446 - val_acc: 0.7630\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0451 - acc: 0.7560 - val_loss: 0.0443 - val_acc: 0.7652\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0448 - acc: 0.7581 - val_loss: 0.0439 - val_acc: 0.7667\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0445 - acc: 0.7599 - val_loss: 0.0436 - val_acc: 0.7691\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0442 - acc: 0.7621 - val_loss: 0.0433 - val_acc: 0.7707\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0439 - acc: 0.7642 - val_loss: 0.0430 - val_acc: 0.7721\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0436 - acc: 0.7659 - val_loss: 0.0427 - val_acc: 0.7746\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0433 - acc: 0.7677 - val_loss: 0.0424 - val_acc: 0.7770\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0430 - acc: 0.7693 - val_loss: 0.0421 - val_acc: 0.7789\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0427 - acc: 0.7706 - val_loss: 0.0418 - val_acc: 0.7804\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0424 - acc: 0.7724 - val_loss: 0.0415 - val_acc: 0.7819\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0421 - acc: 0.7744 - val_loss: 0.0412 - val_acc: 0.7845\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0418 - acc: 0.7764 - val_loss: 0.0409 - val_acc: 0.7864\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0415 - acc: 0.7779 - val_loss: 0.0406 - val_acc: 0.7879\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0413 - acc: 0.7797 - val_loss: 0.0403 - val_acc: 0.7892\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0410 - acc: 0.7814 - val_loss: 0.0401 - val_acc: 0.7910\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0407 - acc: 0.7835 - val_loss: 0.0398 - val_acc: 0.7930\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0405 - acc: 0.7853 - val_loss: 0.0395 - val_acc: 0.7953\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s - loss: 0.0402 - acc: 0.7872 - val_loss: 0.0393 - val_acc: 0.7979\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0399 - acc: 0.7890 - val_loss: 0.0390 - val_acc: 0.7993\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0397 - acc: 0.7908 - val_loss: 0.0387 - val_acc: 0.8019\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0394 - acc: 0.7925 - val_loss: 0.0385 - val_acc: 0.8036\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0392 - acc: 0.7944 - val_loss: 0.0382 - val_acc: 0.8047\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0389 - acc: 0.7958 - val_loss: 0.0380 - val_acc: 0.8065\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0387 - acc: 0.7974 - val_loss: 0.0377 - val_acc: 0.8080\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0384 - acc: 0.7993 - val_loss: 0.0375 - val_acc: 0.8096\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0382 - acc: 0.8012 - val_loss: 0.0373 - val_acc: 0.8105\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0380 - acc: 0.8031 - val_loss: 0.0370 - val_acc: 0.8119\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0377 - acc: 0.8048 - val_loss: 0.0368 - val_acc: 0.8138\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0375 - acc: 0.8071 - val_loss: 0.0365 - val_acc: 0.8153\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0373 - acc: 0.8088 - val_loss: 0.0363 - val_acc: 0.8174\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0371 - acc: 0.8102 - val_loss: 0.0361 - val_acc: 0.8193\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0368 - acc: 0.8120 - val_loss: 0.0359 - val_acc: 0.8201\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0366 - acc: 0.8137 - val_loss: 0.0356 - val_acc: 0.8223\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0364 - acc: 0.8153 - val_loss: 0.0354 - val_acc: 0.8236\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0362 - acc: 0.8165 - val_loss: 0.0352 - val_acc: 0.8254\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0360 - acc: 0.8177 - val_loss: 0.0350 - val_acc: 0.8267\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0358 - acc: 0.8193 - val_loss: 0.0348 - val_acc: 0.8279\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0356 - acc: 0.8206 - val_loss: 0.0346 - val_acc: 0.8298\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0354 - acc: 0.8221 - val_loss: 0.0344 - val_acc: 0.8311\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0352 - acc: 0.8233 - val_loss: 0.0342 - val_acc: 0.8327\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0350 - acc: 0.8246 - val_loss: 0.0340 - val_acc: 0.8338\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0348 - acc: 0.8258 - val_loss: 0.0338 - val_acc: 0.8359\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0346 - acc: 0.8269 - val_loss: 0.0336 - val_acc: 0.8370\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0344 - acc: 0.8281 - val_loss: 0.0334 - val_acc: 0.8390\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0342 - acc: 0.8294 - val_loss: 0.0332 - val_acc: 0.8398\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0340 - acc: 0.8307 - val_loss: 0.0330 - val_acc: 0.8411\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0338 - acc: 0.8314 - val_loss: 0.0328 - val_acc: 0.8416\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0336 - acc: 0.8326 - val_loss: 0.0326 - val_acc: 0.8423\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0335 - acc: 0.8339 - val_loss: 0.0325 - val_acc: 0.8434\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0333 - acc: 0.8349 - val_loss: 0.0323 - val_acc: 0.8444\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0331 - acc: 0.8359 - val_loss: 0.0321 - val_acc: 0.8453\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0329 - acc: 0.8371 - val_loss: 0.0319 - val_acc: 0.8462\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0328 - acc: 0.8381 - val_loss: 0.0318 - val_acc: 0.8476\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0326 - acc: 0.8390 - val_loss: 0.0316 - val_acc: 0.8488\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0324 - acc: 0.8399 - val_loss: 0.0314 - val_acc: 0.8498\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0323 - acc: 0.8410 - val_loss: 0.0313 - val_acc: 0.8508\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0321 - acc: 0.8418 - val_loss: 0.0311 - val_acc: 0.8514\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0319 - acc: 0.8427 - val_loss: 0.0309 - val_acc: 0.8517\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0318 - acc: 0.8432 - val_loss: 0.0308 - val_acc: 0.8528\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0316 - acc: 0.8439 - val_loss: 0.0306 - val_acc: 0.8536\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0315 - acc: 0.8447 - val_loss: 0.0305 - val_acc: 0.8542\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0313 - acc: 0.8457 - val_loss: 0.0303 - val_acc: 0.8550\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0312 - acc: 0.8463 - val_loss: 0.0302 - val_acc: 0.8553\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0310 - acc: 0.8469 - val_loss: 0.0300 - val_acc: 0.8560\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0309 - acc: 0.8480 - val_loss: 0.0299 - val_acc: 0.8563\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0307 - acc: 0.8487 - val_loss: 0.0297 - val_acc: 0.8567\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0306 - acc: 0.8492 - val_loss: 0.0296 - val_acc: 0.8577\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0304 - acc: 0.8498 - val_loss: 0.0294 - val_acc: 0.8581\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0303 - acc: 0.8505 - val_loss: 0.0293 - val_acc: 0.8586\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0302 - acc: 0.8509 - val_loss: 0.0292 - val_acc: 0.8587\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0300 - acc: 0.8516 - val_loss: 0.0290 - val_acc: 0.8589\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0299 - acc: 0.8521 - val_loss: 0.0289 - val_acc: 0.8595\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0298 - acc: 0.8526 - val_loss: 0.0287 - val_acc: 0.8598\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0296 - acc: 0.8529 - val_loss: 0.0286 - val_acc: 0.8602\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0295 - acc: 0.8533 - val_loss: 0.0285 - val_acc: 0.8608\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0294 - acc: 0.8538 - val_loss: 0.0284 - val_acc: 0.8612\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0292 - acc: 0.8544 - val_loss: 0.0282 - val_acc: 0.8616\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0291 - acc: 0.8547 - val_loss: 0.0281 - val_acc: 0.8616\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0290 - acc: 0.8554 - val_loss: 0.0280 - val_acc: 0.8623\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0289 - acc: 0.8559 - val_loss: 0.0279 - val_acc: 0.8629\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s - loss: 0.0288 - acc: 0.8565 - val_loss: 0.0277 - val_acc: 0.8632\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0286 - acc: 0.8570 - val_loss: 0.0276 - val_acc: 0.8639\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0285 - acc: 0.8572 - val_loss: 0.0275 - val_acc: 0.8641\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0284 - acc: 0.8581 - val_loss: 0.0274 - val_acc: 0.8649\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0283 - acc: 0.8585 - val_loss: 0.0273 - val_acc: 0.8657\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0282 - acc: 0.8588 - val_loss: 0.0272 - val_acc: 0.8659\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0281 - acc: 0.8593 - val_loss: 0.0270 - val_acc: 0.8663\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0279 - acc: 0.8596 - val_loss: 0.0269 - val_acc: 0.8672\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0278 - acc: 0.8600 - val_loss: 0.0268 - val_acc: 0.8676\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0277 - acc: 0.8602 - val_loss: 0.0267 - val_acc: 0.8679\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0276 - acc: 0.8606 - val_loss: 0.0266 - val_acc: 0.8682\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 1s - loss: 0.0275 - acc: 0.8610 - val_loss: 0.0265 - val_acc: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe729e16630>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "         y_train,\n",
    "         batch_size=124,\n",
    "         epochs=200,\n",
    "         verbose=1,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
